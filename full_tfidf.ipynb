{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"full_tfidf.ipynb","provenance":[],"authorship_tag":"ABX9TyN49PdH1IZy90bEy7moT7Iw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNj86L_6BMu0","executionInfo":{"status":"ok","timestamp":1649790896144,"user_tz":240,"elapsed":1096,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"1165c2b8-9dc4-41f9-cc0c-ab049603b1c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","path = '/content/drive/My Drive/STAT457'\n","os.chdir(path)\n","os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOVCAYo0BODr","executionInfo":{"status":"ok","timestamp":1649790896146,"user_tz":240,"elapsed":8,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"29e2c62a-337f-40a0-8ffe-f0dbe4a10e19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data.ipynb',\n"," 'data',\n"," 'trained.ipynb',\n"," 'csvData.csv',\n"," 'tfidf_xgb.csv',\n"," 'Untitled0.ipynb']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["!pip install mpld3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3fG5derIseI","executionInfo":{"status":"ok","timestamp":1649790899673,"user_tz":240,"elapsed":3533,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"b025c058-e872-46e5-e14e-e9d3f13cd671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mpld3 in /usr/local/lib/python3.7/dist-packages (0.5.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mpld3) (2.11.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mpld3) (3.2.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mpld3) (2.0.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3) (1.4.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3) (1.21.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mpld3) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mpld3) (3.10.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mpld3) (1.15.0)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.stem.snowball import SnowballStemmer\n","import re\n","import os\n","import codecs\n","from sklearn import feature_extraction, model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n","import mpld3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWQFc3Q8BjaZ","executionInfo":{"status":"ok","timestamp":1649790900288,"user_tz":240,"elapsed":631,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"c166a40b-08fa-4748-eb70-e6030b0c4cc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["full = pd.read_csv(\"data/W22_P2_full.csv\",encoding='gb18030')\n","train = pd.read_csv(\"data/W22_P2_train.csv\",encoding='gb18030')\n","test = pd.read_csv(\"data/W22_P2_test.csv\",encoding='gb18030')\n","print(full.head(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RG5Ra63QBk_C","executionInfo":{"status":"ok","timestamp":1649790900933,"user_tz":240,"elapsed":649,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"914c3c2b-2b61-40e0-df9a-9000d95e2184"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id                                        description\n","0  9014   Docu-drama inspired by the life of Bartolomeo...\n","1  2923   Jos鑼?is a passionate young man in the Dominic...\n","2   313   Imposing, austere gray buildings dominate a s...\n","3  8292   In the multiplex era, a few days prior to his...\n","4  4131   Edmund Purdom narrates a pseudo-documentary a...\n"]}]},{"cell_type":"code","source":["train_y = train[[\"genre\"]]\n","train_x = train[[\"description\"]]\n","description = full[[\"description\"]]\n","test_x = test[[\"description\"]]\n","test_id = test[[\"id\"]]"],"metadata":{"id":"hxnzz2RyI4cP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y = np.array(train_y).tolist()\n","train_x = np.array(train_x).tolist()\n","description = np.array(description).tolist()\n","test_x = np.array(test_x).tolist()\n","train_y = [i[0] for i in train_y]\n","train_x = [i[0] for i in train_x]\n","description = [i[0] for i in description]\n","test_x = [i[0] for i in test_x]\n","test_id = [int(test_id.loc[i]) for i in range(len(test_id))]"],"metadata":{"id":"qrNSdU2cJc3m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_x[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjF8whI2hGPL","executionInfo":{"status":"ok","timestamp":1649790902159,"user_tz":240,"elapsed":17,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"335df54d-4763-4079-b031-750b091e6496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" According to the text of St鑼卲hane E.Roy Nine slices of life. Nine stories that intertwine. A satirical comedy. Marc Gauthier, creator of the new \"Dare Communic-Action 鑹? alleged communication guru offers a new approach. But there will always be a gap between theory and practice ... Between nine earthy situations and absurd misunderstandings everyone will try to grow up\"\n"]}]},{"cell_type":"code","source":["# load nltk's English stopwords\n","stopwords = nltk.corpus.stopwords.words('english')\n","print(stopwords[:10])\n","# load nltk's SnowballStemmer as variabled 'stemmer'\n","stemmer = SnowballStemmer(\"english\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9dYbCd7Kwf_","executionInfo":{"status":"ok","timestamp":1649790902161,"user_tz":240,"elapsed":14,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"74087c66-5bb0-48b0-dc6f-c6442ac852d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"]}]},{"cell_type":"code","source":["# *tokenize_and_stem*: tokenizes (splits the synopsis into a list of its respective words (or tokens) and also stems each token\n","# *tokenize_only*: tokenizes the synopsis only\n","# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n","def tokenize_and_stem(text):\n","    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n","    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n","    filtered_tokens = []\n","    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n","    for token in tokens:\n","        if re.search('[a-zA-Z]', token):\n","            filtered_tokens.append(token)\n","    stems = [stemmer.stem(t) for t in filtered_tokens]\n","    return stems\n","\n","\n","def tokenize_only(text):\n","    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n","    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n","    filtered_tokens = []\n","    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n","    for token in tokens:\n","        if re.search('[a-zA-Z]', token):\n","            filtered_tokens.append(token)\n","    return filtered_tokens"],"metadata":{"id":"-q9ZT9ymLNHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["description[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"WcCEHhioMITK","executionInfo":{"status":"ok","timestamp":1649790902292,"user_tz":240,"elapsed":18,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"7b2ab7b5-df56-4286-d0ac-63652fe62eb0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Docu-drama inspired by the life of Bartolomeo Scappi, the personal chef of the 16th century Pontiff, Pope Pius V. Film looks at the cooking implements, ingredients and recipes used by Scappi, who has been called 鎵?the Michelangelo of the kitchen. 閽?\\n2909, short , Unseen in the background is fate and it\\'s about to start a journey with Officer Trevor Lewis who is dealing with the tragic loss of his son. The grief he feels haunts his soul and yet somehow a small musical snow globe is all that is needed to begin the healing. A journey good deeds and a prayer all come together in a story of hope.\"'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["totalvocab_stemmed = []\n","totalvocab_tokenized = []\n","\n","for i in description:\n","    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n","    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n","    \n","    allwords_tokenized = tokenize_only(i)\n","    totalvocab_tokenized.extend(allwords_tokenized)"],"metadata":{"id":"mr6DU5jeL8q9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_stemmed = []\n","test_tokenized = []\n","for i in test_x:\n","    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n","    test_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n","    \n","    allwords_tokenized = tokenize_only(i)\n","    test_tokenized.extend(allwords_tokenized)"],"metadata":{"id":"YNfMlqUloOKa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n","print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"],"metadata":{"id":"Q86VtCsfgYhN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_frame"],"metadata":{"id":"j3M5X0AwgUJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","#define vectorizer parameters\n","tfidf_vectorizer = TfidfVectorizer(max_df = 0.8, min_df = 0.01,stop_words='english',use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n","\n","tfidf_matrix = tfidf_vectorizer.fit_transform(description) #fit the vectorizer to synopses\n","\n","print(tfidf_matrix.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zvyGbz_guWD","executionInfo":{"status":"ok","timestamp":1649791171972,"user_tz":240,"elapsed":47332,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"924a4c75-d8ad-43eb-c89f-690face7feba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n","  % sorted(inconsistent)\n"]},{"output_type":"stream","name":"stdout","text":["(15998, 904)\n"]}]},{"cell_type":"code","source":["print(len(train_x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oXhw33LOztw","executionInfo":{"status":"ok","timestamp":1649791441126,"user_tz":240,"elapsed":118,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"c70cf81e-b1cc-402d-bcb0-d0449aeeb9f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["9998\n"]}]},{"cell_type":"code","source":["print(tfidf_matrix[0:9998,].toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGLIN0JrO8yT","executionInfo":{"status":"ok","timestamp":1649791480445,"user_tz":240,"elapsed":159,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"cc161041-e49c-47a5-f0ab-551bdf798d16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.07268798 0.         0.         ... 0.         0.         0.        ]\n"," [0.06325744 0.         0.         ... 0.         0.         0.        ]\n"," [0.08012092 0.         0.         ... 0.         0.         0.        ]\n"," ...\n"," [0.06954037 0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":["print(tfidf_matrix.toarray())\n","tfidf_vectorizer.get_feature_names()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ev9zjs8ZF5Pg","executionInfo":{"status":"ok","timestamp":1649791391206,"user_tz":240,"elapsed":116,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"d9cad4c2-4a9c-4c5f-d5b2-f29291feadf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.07268798 0.         0.         ... 0.         0.         0.        ]\n"," [0.06325744 0.         0.         ... 0.         0.         0.        ]\n"," [0.08012092 0.         0.         ... 0.         0.         0.        ]\n"," ...\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["[\"'s\",\n"," \"'s life\",\n"," 'abandon',\n"," 'abl',\n"," 'abus',\n"," 'accept',\n"," 'accid',\n"," 'accompani',\n"," 'achiev',\n"," 'act',\n"," 'action',\n"," 'activ',\n"," 'actor',\n"," 'actress',\n"," 'actual',\n"," 'addict',\n"," 'adopt',\n"," 'adult',\n"," 'adventur',\n"," 'affair',\n"," 'affect',\n"," 'age',\n"," 'agent',\n"," 'ago',\n"," 'agre',\n"," 'aid',\n"," 'air',\n"," 'alcohol',\n"," 'allow',\n"," 'alon',\n"," 'alreadi',\n"," 'alway',\n"," 'america',\n"," 'american',\n"," 'ancient',\n"," 'angel',\n"," 'ani',\n"," 'anim',\n"," 'anoth',\n"," 'answer',\n"," 'anyon',\n"," 'anyth',\n"," 'apart',\n"," 'appear',\n"," 'approach',\n"," 'archiv',\n"," 'area',\n"," 'arm',\n"," 'armi',\n"," 'arrest',\n"," 'arriv',\n"," 'art',\n"," 'artist',\n"," 'ask',\n"," 'assist',\n"," 'attack',\n"," 'attempt',\n"," 'attend',\n"," 'attent',\n"," 'attract',\n"," 'audienc',\n"," 'author',\n"," 'award',\n"," 'away',\n"," 'babi',\n"," 'background',\n"," 'bad',\n"," 'band',\n"," 'bank',\n"," 'bar',\n"," 'base',\n"," 'battl',\n"," 'beauti',\n"," 'becam',\n"," 'becaus',\n"," 'becom',\n"," 'befor',\n"," 'began',\n"," 'begin',\n"," 'believ',\n"," 'best',\n"," 'best friend',\n"," 'better',\n"," 'big',\n"," 'biggest',\n"," 'birth',\n"," 'black',\n"," 'bodi',\n"," 'bond',\n"," 'book',\n"," 'born',\n"," 'boss',\n"," 'boy',\n"," 'boyfriend',\n"," 'break',\n"," 'bring',\n"," 'british',\n"," 'brother',\n"," 'brought',\n"," 'build',\n"," 'busi',\n"," 'buy',\n"," 'ca',\n"," \"ca n't\",\n"," 'california',\n"," 'came',\n"," 'camera',\n"," 'camp',\n"," 'captur',\n"," 'car',\n"," 'care',\n"," 'career',\n"," 'carri',\n"," 'case',\n"," 'cast',\n"," 'catch',\n"," 'caught',\n"," 'caus',\n"," 'celebr',\n"," 'center',\n"," 'central',\n"," 'centuri',\n"," 'certain',\n"," 'challeng',\n"," 'chanc',\n"," 'chang',\n"," 'charact',\n"," 'charg',\n"," 'charm',\n"," 'child',\n"," 'childhood',\n"," 'children',\n"," 'choic',\n"," 'choos',\n"," 'chronicl',\n"," 'church',\n"," 'cinema',\n"," 'citi',\n"," 'civil',\n"," 'claim',\n"," 'class',\n"," 'classic',\n"," 'clear',\n"," 'close',\n"," 'club',\n"," 'collect',\n"," 'colleg',\n"," 'color',\n"," 'combin',\n"," 'come',\n"," 'comedi',\n"," 'comic',\n"," 'commit',\n"," 'common',\n"," 'communiti',\n"," 'compani',\n"," 'competit',\n"," 'complet',\n"," 'complex',\n"," 'complic',\n"," 'concern',\n"," 'condit',\n"," 'conflict',\n"," 'confront',\n"," 'connect',\n"," 'consequ',\n"," 'consid',\n"," 'constant',\n"," 'construct',\n"," 'contemporari',\n"," 'continu',\n"," 'control',\n"," 'controversi',\n"," 'convers',\n"," 'convinc',\n"," 'countri',\n"," 'coupl',\n"," 'cours',\n"," 'court',\n"," 'cover',\n"," 'crazi',\n"," 'creat',\n"," 'creativ',\n"," 'crew',\n"," 'crime',\n"," 'crimin',\n"," 'crisi',\n"," 'critic',\n"," 'cross',\n"," 'cultur',\n"," 'current',\n"," 'custom',\n"," 'cut',\n"," 'daili',\n"," 'danc',\n"," 'danger',\n"," 'dark',\n"," 'date',\n"," 'daughter',\n"," 'david',\n"," 'day',\n"," 'dead',\n"," 'deal',\n"," 'death',\n"," 'decad',\n"," 'decid',\n"," 'decis',\n"," 'deep',\n"," 'demand',\n"," 'depict',\n"," 'describ',\n"," 'desert',\n"," 'design',\n"," 'desir',\n"," 'desper',\n"," 'despit',\n"," 'destroy',\n"," 'determin',\n"," 'develop',\n"," 'did',\n"," 'die',\n"," 'differ',\n"," 'difficult',\n"," 'direct',\n"," 'director',\n"," 'disappear',\n"," 'discov',\n"," 'discuss',\n"," 'divorc',\n"," 'doctor',\n"," 'document',\n"," 'documentari',\n"," 'doe',\n"," \"doe n't\",\n"," 'dog',\n"," 'door',\n"," 'dr.',\n"," 'drama',\n"," 'dramat',\n"," 'draw',\n"," 'dream',\n"," 'drink',\n"," 'drive',\n"," 'driver',\n"," 'drug',\n"," 'dure',\n"," 'earli',\n"," 'earn',\n"," 'earth',\n"," 'easi',\n"," 'east',\n"," 'econom',\n"," 'educ',\n"," 'effect',\n"," 'effort',\n"," 'elder',\n"," 'els',\n"," 'embark',\n"," 'emerg',\n"," 'emot',\n"," 'encount',\n"," 'end',\n"," 'engag',\n"," 'enjoy',\n"," 'enter',\n"," 'entertain',\n"," 'entir',\n"," 'environ',\n"," 'episod',\n"," 'escap',\n"," 'especi',\n"," 'establish',\n"," 'europ',\n"," 'event',\n"," 'eventu',\n"," 'everi',\n"," 'everyday',\n"," 'everyon',\n"," 'everyth',\n"," 'examin',\n"," 'excit',\n"," 'execut',\n"," 'exist',\n"," 'expect',\n"," 'experi',\n"," 'expert',\n"," 'explain',\n"," 'explor',\n"," 'expos',\n"," 'express',\n"," 'extraordinari',\n"," 'extrem',\n"," 'eye',\n"," 'face',\n"," 'fact',\n"," 'fail',\n"," 'faith',\n"," 'fall',\n"," 'fall love',\n"," 'fame',\n"," 'famili',\n"," 'famous',\n"," 'fan',\n"," 'far',\n"," 'farm',\n"," 'fascin',\n"," 'fashion',\n"," 'fate',\n"," 'father',\n"," \"father 's\",\n"," 'fear',\n"," 'featur',\n"," 'feel',\n"," 'fellow',\n"," 'femal',\n"," 'festiv',\n"," 'fiction',\n"," 'field',\n"," 'fight',\n"," 'figur',\n"," 'film',\n"," 'filmmak',\n"," 'final',\n"," 'financi',\n"," 'focus',\n"," 'follow',\n"," 'food',\n"," 'footag',\n"," 'forc',\n"," 'forev',\n"," 'form',\n"," 'fortun',\n"," 'free',\n"," 'freedom',\n"," 'french',\n"," 'friend',\n"," 'friendship',\n"," 'fun',\n"," 'funni',\n"," 'futur',\n"," 'gain',\n"," 'game',\n"," 'gang',\n"," 'gather',\n"," 'gay',\n"," 'general',\n"," 'generat',\n"," 'georg',\n"," 'german',\n"," 'girl',\n"," 'girlfriend',\n"," 'given',\n"," 'global',\n"," 'goal',\n"," 'god',\n"," 'goe',\n"," 'gone',\n"," 'good',\n"," 'got',\n"," 'govern',\n"," 'great',\n"," 'greatest',\n"," 'ground',\n"," 'group',\n"," 'grow',\n"," 'guest',\n"," 'guid',\n"," 'guy',\n"," 'half',\n"," 'hand',\n"," 'happen',\n"," 'happi',\n"," 'hard',\n"," 'haunt',\n"," 'head',\n"," 'health',\n"," 'hear',\n"," 'heart',\n"," 'help',\n"," 'hero',\n"," 'hidden',\n"," 'hide',\n"," 'high',\n"," 'high school',\n"," 'hilari',\n"," 'hire',\n"," 'histor',\n"," 'histori',\n"," 'hit',\n"," 'hold',\n"," 'hollywood',\n"," 'home',\n"," 'hope',\n"," 'hospit',\n"," 'host',\n"," 'hotel',\n"," 'hour',\n"," 'hous',\n"," 'howev',\n"," 'human',\n"," 'humor',\n"," 'husband',\n"," 'idea',\n"," 'ident',\n"," 'ill',\n"," 'imag',\n"," 'imagin',\n"," 'immedi',\n"," 'immigr',\n"," 'impact',\n"," 'import',\n"," 'includ',\n"," 'increas',\n"," 'independ',\n"," 'india',\n"," 'individu',\n"," 'industri',\n"," 'influenc',\n"," 'inform',\n"," 'initi',\n"," 'inner',\n"," 'innoc',\n"," 'insid',\n"," 'insight',\n"," 'inspir',\n"," 'instead',\n"," 'intern',\n"," 'interview',\n"," 'intim',\n"," 'introduc',\n"," 'investig',\n"," 'invit',\n"," 'involv',\n"," 'island',\n"," 'issu',\n"," 'jame',\n"," 'job',\n"," 'john',\n"," 'join',\n"," 'journalist',\n"," 'journey',\n"," 'just',\n"," 'kid',\n"," 'kill',\n"," 'kind',\n"," 'king',\n"," 'know',\n"," 'known',\n"," 'la',\n"," 'lack',\n"," 'ladi',\n"," 'land',\n"," 'landscap',\n"," 'larg',\n"," 'late',\n"," 'later',\n"," 'law',\n"," 'lawyer',\n"," 'lead',\n"," 'leader',\n"," 'learn',\n"," 'leav',\n"," 'led',\n"," 'left',\n"," 'let',\n"," 'letter',\n"," 'lie',\n"," 'life',\n"," 'lifestyl',\n"," 'light',\n"," 'like',\n"," 'limit',\n"," 'line',\n"," 'littl',\n"," 'live',\n"," 'll',\n"," 'local',\n"," 'locat',\n"," 'london',\n"," 'lone',\n"," 'long',\n"," 'longer',\n"," 'look',\n"," 'los',\n"," 'los angel',\n"," 'lose',\n"," 'loss',\n"," 'lost',\n"," 'lot',\n"," 'love',\n"," 'lover',\n"," 'magic',\n"," 'main',\n"," 'major',\n"," 'make',\n"," 'male',\n"," 'man',\n"," \"man 's\",\n"," 'manag',\n"," 'mani',\n"," 'mari',\n"," 'mark',\n"," 'marri',\n"," 'marriag',\n"," 'master',\n"," 'materi',\n"," 'matter',\n"," 'mean',\n"," 'meanwhil',\n"," 'media',\n"," 'medic',\n"," 'meet',\n"," 'member',\n"," 'memori',\n"," 'men',\n"," 'mental',\n"," 'met',\n"," 'michael',\n"," 'middl',\n"," 'militari',\n"," 'million',\n"," 'mind',\n"," 'minut',\n"," 'miss',\n"," 'mission',\n"," 'mix',\n"," 'model',\n"," 'modern',\n"," 'moment',\n"," 'money',\n"," 'month',\n"," 'morn',\n"," 'mother',\n"," 'mountain',\n"," 'movement',\n"," 'movi',\n"," 'mr.',\n"," 'murder',\n"," 'music',\n"," 'musician',\n"," 'mysteri',\n"," \"n't\",\n"," 'narrat',\n"," 'nation',\n"," 'natur',\n"," 'near',\n"," 'need',\n"," 'neighbor',\n"," 'neighborhood',\n"," 'new',\n"," 'new york',\n"," 'new york citi',\n"," 'news',\n"," 'night',\n"," 'normal',\n"," 'north',\n"," 'noth',\n"," 'number',\n"," 'object',\n"," 'obsess',\n"," 'odd',\n"," 'offer',\n"," 'offic',\n"," 'offici',\n"," 'old',\n"," 'older',\n"," 'onc',\n"," 'onli',\n"," 'open',\n"," 'oper',\n"," 'opportun',\n"," 'order',\n"," 'organ',\n"," 'origin',\n"," 'outsid',\n"," 'overcom',\n"," 'owner',\n"," 'pain',\n"," 'paint',\n"," 'parent',\n"," 'pari',\n"," 'park',\n"," 'parti',\n"," 'particip',\n"," 'particular',\n"," 'partner',\n"," 'pass',\n"," 'passion',\n"," 'past',\n"," 'path',\n"," 'paul',\n"," 'pay',\n"," 'peac',\n"," 'peopl',\n"," 'perfect',\n"," 'perform',\n"," 'period',\n"," 'person',\n"," 'perspect',\n"," 'peter',\n"," 'photograph',\n"," 'physic',\n"," 'pick',\n"," 'pictur',\n"," 'piec',\n"," 'place',\n"," 'plan',\n"," 'play',\n"," 'player',\n"," 'plot',\n"," 'point',\n"," 'polic',\n"," 'polit',\n"," 'poor',\n"," 'popular',\n"," 'portrait',\n"," 'portray',\n"," 'posit',\n"," 'possibl',\n"," 'power',\n"," 'practic',\n"," 'pregnant',\n"," 'prepar',\n"," 'present',\n"," 'presid',\n"," 'prison',\n"," 'privat',\n"," 'problem',\n"," 'process',\n"," 'produc',\n"," 'product',\n"," 'profession',\n"," 'professor',\n"," 'program',\n"," 'project',\n"," 'promis',\n"," 'protect',\n"," 'prove',\n"," 'provid',\n"," 'public',\n"," 'pull',\n"," 'pursu',\n"," 'push',\n"," 'quest',\n"," 'question',\n"," 'quick',\n"," 'quit',\n"," 'race',\n"," 'rais',\n"," 'rare',\n"," 'reach',\n"," 'read',\n"," 'readi',\n"," 'real',\n"," 'realiti',\n"," 'realiz',\n"," 'realli',\n"," 'reason',\n"," 'receiv',\n"," 'recent',\n"," 'record',\n"," 'reflect',\n"," 'refus',\n"," 'region',\n"," 'relat',\n"," 'relationship',\n"," 'releas',\n"," 'remain',\n"," 'rememb',\n"," 'report',\n"," 'repres',\n"," 'rescu',\n"," 'research',\n"," 'resid',\n"," 'respect',\n"," 'respons',\n"," 'rest',\n"," 'result',\n"," 'retir',\n"," 'return',\n"," 'reveal',\n"," 'rich',\n"," 'ride',\n"," 'right',\n"," 'rise',\n"," 'risk',\n"," 'river',\n"," 'road',\n"," 'robert',\n"," 'rock',\n"," 'role',\n"," 'romant',\n"," 'room',\n"," 'rule',\n"," 'run',\n"," 'save',\n"," 'say',\n"," 'scene',\n"," 'school',\n"," 'screen',\n"," 'sea',\n"," 'search',\n"," 'season',\n"," 'second',\n"," 'secret',\n"," 'secur',\n"," 'seek',\n"," 'seen',\n"," 'self',\n"," 'sell',\n"," 'send',\n"," 'sens',\n"," 'sent',\n"," 'separ',\n"," 'seri',\n"," 'serv',\n"," 'servic',\n"," 'set',\n"," 'seven',\n"," 'sever',\n"," 'sex',\n"," 'sexual',\n"," 'share',\n"," 'shock',\n"," 'shoot',\n"," 'shop',\n"," 'short',\n"," 'short film',\n"," 'shot',\n"," 'sign',\n"," 'simpl',\n"," 'sinc',\n"," 'singl',\n"," 'sister',\n"," 'sit',\n"," 'situat',\n"," 'sleep',\n"," 'small',\n"," 'small town',\n"," 'social',\n"," 'societi',\n"," 'soldier',\n"," 'someon',\n"," 'someth',\n"," 'sometim',\n"," 'son',\n"," 'song',\n"," 'soon',\n"," 'soul',\n"," 'sound',\n"," 'south',\n"," 'space',\n"," 'speak',\n"," 'special',\n"," 'spend',\n"," 'spirit',\n"," 'spiritu',\n"," 'sport',\n"," 'stage',\n"," 'stand',\n"," 'star',\n"," 'start',\n"," 'state',\n"," 'station',\n"," 'stay',\n"," 'steal',\n"," 'step',\n"," 'stop',\n"," 'store',\n"," 'stori',\n"," 'strang',\n"," 'stranger',\n"," 'street',\n"," 'strong',\n"," 'struggl',\n"," 'student',\n"," 'studi',\n"," 'studio',\n"," 'style',\n"," 'subject',\n"," 'success',\n"," 'sudden',\n"," 'suffer',\n"," 'suicid',\n"," 'summer',\n"," 'support',\n"," 'surpris',\n"," 'surround',\n"," 'surviv',\n"," 'taken',\n"," 'tale',\n"," 'talent',\n"," 'talk',\n"," 'teach',\n"," 'teacher',\n"," 'team',\n"," 'teenag',\n"," 'televis',\n"," 'tell',\n"," 'tell stori',\n"," 'term',\n"," 'test',\n"," 'themselv',\n"," 'thing',\n"," 'think',\n"," 'thought',\n"," 'thousand',\n"," 'threaten',\n"," 'time',\n"," 'titl',\n"," 'today',\n"," 'togeth',\n"," 'told',\n"," 'took',\n"," 'touch',\n"," 'tour',\n"," 'town',\n"," 'track',\n"," 'tradit',\n"," 'tragedi',\n"," 'tragic',\n"," 'train',\n"," 'transform',\n"," 'travel',\n"," 'tri',\n"," 'trip',\n"," 'troubl',\n"," 'true',\n"," 'truli',\n"," 'truth',\n"," 'turn',\n"," 'tv',\n"," 'ultim',\n"," 'unabl',\n"," 'uncl',\n"," 'understand',\n"," 'unexpect',\n"," 'unfold',\n"," 'unfortun',\n"," 'uniqu',\n"," 'unit',\n"," 'unit state',\n"," 'univers',\n"," 'unknown',\n"," 'urban',\n"," 'use',\n"," 'valu',\n"," 'various',\n"," 'veri',\n"," 'victim',\n"," 'video',\n"," 'view',\n"," 'viewer',\n"," 'villag',\n"," 'violenc',\n"," 'visit',\n"," 'visual',\n"," 'voic',\n"," 'wait',\n"," 'wake',\n"," 'walk',\n"," 'wall',\n"," 'want',\n"," 'war',\n"," 'watch',\n"," 'water',\n"," 'way',\n"," 'wealthi',\n"," 'wed',\n"," 'week',\n"," 'went',\n"," 'west',\n"," 'whi',\n"," 'white',\n"," 'widow',\n"," 'wife',\n"," 'wild',\n"," 'win',\n"," 'wish',\n"," 'wit',\n"," 'woman',\n"," 'women',\n"," 'wonder',\n"," 'word',\n"," 'work',\n"," 'worker',\n"," 'world',\n"," \"world 's\",\n"," 'wors',\n"," 'write',\n"," 'writer',\n"," 'written',\n"," 'wrong',\n"," 'year',\n"," 'year ago',\n"," 'year later',\n"," 'year old',\n"," 'york',\n"," 'york citi',\n"," 'young',\n"," 'young man',\n"," 'young woman',\n"," 'younger',\n"," 'youth']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["import xgboost\n","from xgboost import XGBClassifier"],"metadata":{"id":"HJDuB-e9khIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = preprocessing.LabelEncoder()\n","t_y = encoder.fit_transform(train_y)"],"metadata":{"id":"x7zlYi13mfsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(genre[0:10])"],"metadata":{"id":"zLL4V5a_mvLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y[0:10]"],"metadata":{"id":"NB-xgcdXms03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_model(classifier, feature_vector_train, label, feature_vector_test, is_neural_net=False):\n","    # fit the training dataset on the classifier\n","    classifier.fit(feature_vector_train, label)\n","    # predict the labels on validation dataset\n","    predictions = classifier.predict(feature_vector_test)\n","    return predictions"],"metadata":{"id":"vv6vOQYEpqm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tfidf_train_x = tfidf_matrix[0:9998,:]\n","tfidf_test_x = tfidf_matrix[9998:,:]\n","print(tfidf_train_x.shape)\n","print(tfidf_test_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnwrLRMxPQ20","executionInfo":{"status":"ok","timestamp":1649791618792,"user_tz":240,"elapsed":157,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"70e66d42-3dc0-4812-e7e2-ef551f36c163"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(9998, 904)\n","(6000, 904)\n"]}]},{"cell_type":"code","source":["type(tfidf_test_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvrqIWzTSmnH","executionInfo":{"status":"ok","timestamp":1649792423018,"user_tz":240,"elapsed":173,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"3b89c25f-535b-4189-b857-9f8238115b52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["scipy.sparse.csr.csr_matrix"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["pred = test_model(xgboost.XGBClassifier(), tfidf_train_x, train_y, tfidf_test_x)"],"metadata":{"id":"hhNySMZakoyM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fw0V8JbzrdBY","executionInfo":{"status":"ok","timestamp":1649791799856,"user_tz":240,"elapsed":148,"user":{"displayName":"amera guo","userId":"00962841590747645132"}},"outputId":"ac9a3ecf-f3bb-42c7-c580-10487828b567"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' comedy ' ' documentary ' ' documentary ' ... ' documentary ' ' short '\n"," ' comedy ']\n"]}]},{"cell_type":"code","source":["pred1 = list(pred.copy())\n","pred1 = [\" documentary \" if i ==1 else i for i in pred1]\n","pred1 = [\" short \" if i ==3 else i for i in pred1]\n","pred1 = [\" comedy \" if i ==0 else i for i in pred1]\n","pred1 = [\" drama \" if i ==2 else i for i in pred1]"],"metadata":{"id":"WmhPieBjqCiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred1"],"metadata":{"id":"zgcAdnJ7rl2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","csvFile = open(\"tfidf_xgb.csv\", \"w\")  \n","writer = csv.writer(csvFile)\n","#先写入columns_name\n","writer.writerow([\"id\", \"genre\"])\n","for i in range(len(pred)):\n","    writer.writerow([test_id[i], pred[i]])\n","csvFile.close()"],"metadata":{"id":"6UY78b9vqIVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.savetxt('tfidf.csv', tfidf_matrix.toarray(), delimiter = ',')"],"metadata":{"id":"rBPT0gsoTU5Z"},"execution_count":null,"outputs":[]}]}